{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Statistical learning_ refers to set of tools for _understanding data_. These tools can be classified as _supervised_ or _unsupervised_.\n",
    "\n",
    "**Supervised Learning**  \n",
    "In a supervised learning problem, for each observation of the predictor measurement(s) $x_i, i=1,...,n$ there is an associated response measurement $y_i$. We'll fit a model that relates the response to the prodictors, with the aim of accurately predicting the response for future observations (*prediction*) or better understand the relationship between the response and the prodictors(*inference*).\n",
    "\n",
    "Supervised learning approaches include methods such as linear regression, logistic regression, Generalized Additive Models (GAMs), boosting and support vector machines.\n",
    "\n",
    "**Unsupervised Learning**  \n",
    "In a unsupervised learning describes a situation in which for every observation $i=1,...,n$,we observe measurements for input variables but no associated response $y_i$ is measured.\n",
    "We may use statistical learning tools such as clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Notation for Statistical Model\n",
    "A statistical model will have a $p$ number of input variables denoted by the system $X$, with a subscript to distinguish them, $X=(X_1, X_2,...,X_p)$. The inputs may be referred to as, *predictors, independent variables, features*.\n",
    "\n",
    "The output variable is often called the _response or dependent variable_ and is typically denoted by $Y$.\n",
    "\n",
    "Generally, the relationship can be written in the general form,\n",
    "$$Y = f(X)+\\epsilon$$\n",
    "\n",
    "Here $f$ is some fixed but unknown function of $X_1,...,X_p$ and $\\epsilon$ is a random _error term_, which is independent of $X$ and has mean zero. $\\epsilon$ may contain unmeasured variables that are effect Y, and unmeasurable variations.\n",
    "\n",
    "### Estimating $f$ for prediction and/or inference\n",
    "#### Prediction\n",
    "In a situation a set of inputs X are readily avaialble, but the output Y cannot be easily obtained. In this setting Y can be predicted using\n",
    "$$\\hat Y=\\hat f(X)$$\n",
    "THe accuracy of $\\hat Y$ as a predictor for $Y$ depends on two qualities; the _reducible error_, _irreducible error_.\n",
    "Since $\\hat f$ is an estimate for $f$, some error will exist simply due to the approximation. This error is *reducible* becouse we can potentially improve the accuracy of $\\hat f$ by using the most appropriate statistical learning technique. However, even if it was possible to form a perfect estimate for $f$, there will still be some error in it due to the effect of $\\epsilon$. This error is considered _irreducible_ error, becouse no matter how well $f$ is estimated, we cannot reduce the error introduced by $\\epsilon$\n",
    "\n",
    "#### Inference\n",
    "In other situations we may be interested in understanding the way that $Y$ is affected as $X_1,...,X_p$ changes. In such situations we may need to understand how $Y$ changes as a function of $X_1,...,X_p$, and we'll need to know the exact form of $\\hat f$.\n",
    "* Identify the few *important* predictors among a large set of possible variables.\n",
    "* The relationship between the response and each predictor. Some predictors may have a positive relationship with $Y$, while others may have the opposite relationship.\n",
    "* Whether the relationship can be modeled using a linear form or a non-linear form. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression vs Classification Problems\n",
    "We tend to refer to problems with a quantitative responses as *regression problems* while those involving a qualitative response are refered as *classification problems*. \n",
    "\n",
    "### Assessing Model Accuracy\n",
    "In a regression setting, the most commonly used measure is the *mean squared error* (MSE), given by;\n",
    "$$MSE=\\frac{1}{n}\\sum^n_{i=1}(y_i-\\hat f(x_i))^2$$ \n",
    "where $\\hat f(x_i) $ is the prediction $\\hat f$ gives for the $i$th observation. The MSE will be small if the prediction responses are very close to the true responses, and will be large if for some of the observations, the predicted and true response differ substantially.\n",
    "\n",
    "The MSE computed using the *training data* that was used to fit the model, is more accurately refered to as the *training MSE*. In general, we are not interested in how well the method works on training data, rather, we are interested in the accuracy of the predictions that we can obtain when we apply our method to previously unseen *test data*.\n",
    "\n",
    "We can use our training observations $\\{(x_1,y_1),(x_2,y_2),...(x_n,y_n\\}$ and obtain the estimate $\\hat f$ by fitting a statistical learning method. We can then compute $\\hat f(x_1),\\hat f(x_2),...,\\hat f(x_n)$. If there are approximately equal to $y_1, y_2,..y_n$, then the MSE of the training data will be small. However, what we are interested is knowing whether $\\hat f(x_0)$ is approximately equal to $y_0$, where $(x_0,y_0)$ is a previously unseen test observation, not used to train the statistical learning method. We want to choose a method that will give the lowest *test MSE*.\n",
    "\n",
    "For a classification problem, the accuracy of the estimate $\\hat f$ quantified using the _error rate_,\n",
    "$$\\frac{1}{n}\\sum^n_{i=1}I(y_i \\neq \\hat y_i)$$\n",
    "where $\\hat y_i$ is the predicted class lable for the $i$th observation using $\\hat f$. And $I(y_i \\neq \\hat y_i)$ is an indicator variable that equals 1 if $I(y_i \\neq \\hat y_i)$ and zero if $I(y_i = \\hat y_i)$. Hence _error rate_ computes the fraction of incorrect classifications. The *test error* rate associated with a set of test observations of the form $(x_0,y_0)$ is given by;\n",
    "$$Ave(I(y_0 \\neq \\hat y_0)$$\n",
    "where $\\hat y$ is the predicted class label that result from applying the classifier to the test observation. A *good* classifier is one for which the test error is smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias Variance Trade-Off\n",
    "The expected test MSE, for a given value of $x_0$, can be decomposed into the sum of three fundamental quantities; the *variance* of $\\hat f(x_0)$, the squared *bias* of  $\\hat f(x_0)$ and the variance of the error terms $\\epsilon$. That is,\n",
    "$$E(y_0-\\hat f(x_0))^2=Var(\\hat f(x_0))+[Bias(\\hat f(x_0))]^2+Var(\\epsilon)$$\n",
    "\n",
    "Here the notation $E(y_0-\\hat f(x_0))^2,$ defines the expected test MSE, and refers to the average test MSE that we would obtain if we repeatedly estimated $f$ using a large number of training sets, and tested each at $x_0$. The overall expected test MSE can be comouted by averaging $E(y_0-\\hat f(x_0))^2$ over all possible values of $x_0$ in the test set.\n",
    "\n",
    "Variance of a statistical learning method refers to the amount by which $\\hat f$ would change if it was estimated using a different training data set. Since the training data are used to fit the statistical learning method, different training data sets will result in a different $\\hat f$. Ideally, the estimate for $f$ should not vary too much between training sets, however, if a method has high variance then small changes in the training data can result in large changes in $\\hat f$.\n",
    "\n",
    "Bias refers to the error that is introduced by approximating a real-life problem, which might be extreamly complecated, by a much simpler model.\n",
    "\n",
    "Generally, more flexible methods will result in a higher variance and less bias. The relative changes in these quantities determine whether the test MSE increase or decrease. As the flexibility of a method increase, the bias tends to initially decrease faster than the variance increase, however, at some point increase flexibility has little impact on the bias but starts to significantly increase the variance. When this happens the test MSE increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
